{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2923cd1",
   "metadata": {},
   "source": [
    "# Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f9b6b44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'system_desc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msubprocess\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m a, b, c, ad, bd, k, l, h, safex, grid_delta, dims, mdadt1 = \u001b[43msystem_desc\u001b[49m(\u001b[33m'\u001b[39m\u001b[33msuspension_control\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m curdir = os.getcwd()\n\u001b[32m     10\u001b[39m partitions, count = partition_safex(safex, grid_delta, dims)\n",
      "\u001b[31mNameError\u001b[39m: name 'system_desc' is not defined"
     ]
    }
   ],
   "source": [
    "# import \"system_desc\"\n",
    "# import \"generate_model\"\n",
    "# import \"partition_safex\"\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "a, b, c, ad, bd, k, l, h, safex, grid_delta, dims, mdadt1 = system_desc('suspension_control')\n",
    "curdir = os.getcwd()\n",
    "partitions, count = partition_safex(safex, grid_delta, dims)\n",
    "print(f\"Partitioned safe space into {str(count)} grid cells using Polytope.\")\n",
    "Kmax = 20 # hyperperiod\n",
    "mmax = 10 # max misses\n",
    "nl = 2 # number of locations other than l0 and l1's mdadt variant\n",
    "cm_bar = nl-1 # max(a0.keys()) if a0 else 0 # max consec. miss ctr\n",
    "m_bar_max = 2 # Kmax - (Kmax // (cm_bar + 1)) if cm_bar > -1 else 0\n",
    "print(f\"Initial analysis -> {nl} locations, Max consecutive miss (CM)={cm_bar}, Max total miss (M)={m_bar_max}\")\n",
    "\n",
    "# Initialize the specification list\n",
    "spec_list = [{'X': [], 'm_bar': m, 'cm_bar': cm_bar, 'cm': 0, 'K': Kmax} for m in range(m_bar_max + 1)]\n",
    "\n",
    "# Initialize Safety Guard (SG) data structure\n",
    "sg = {m: {} for m in range(m_bar_max + 1)}\n",
    "\n",
    "# --- loop for all possible miss counts --- #\n",
    "for m_j in range(m_bar_max + 1):\n",
    "    for partition in partitions:    \n",
    "        modelfilename = f'{system}_p{count}_K{Kmax}_mbar{m_j}' # +.model\n",
    "        modelfile = os.path.join(curdir, f'{system}', 'modelfiles', modelfilename)\n",
    "        os.makedirs(os.path.dirname(f'{modelfile}.model'), exist_ok=True)\n",
    "        print(f\"\\n--- Generating model for each partition {count} and Verifying for m_bar = {m_j} misses ---\")\n",
    "        generate_model(a, b, c, ad, bd, k, l, h, safex, partition, modelfile, \n",
    "                                                    mdadt1=4, i=nl, Kmax=Kmax, mmax=m_j)\n",
    "        count = count - 1\n",
    "        # result = subprocess.run(['wsl'], capture_output=True, text=True, check=True)\n",
    "        # result = subprocess.run(['../../../flowstar-2.1.0/flowstar', f'< {modelfile}.model'], capture_output=True, text=True, check=True)\n",
    "        # print(\"Command Output:\")\n",
    "        # print(result.stdout)\n",
    "        # print(\"Command Errors (if any):\")\n",
    "        # print(result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClosedLoopSystem:\n",
    "    \"\"\"\n",
    "    Represents the closed-loop control system as described in Section II of the paper.\n",
    "    It encapsulates system matrices and derives the augmented state matrices for\n",
    "    successful (A1) and missed (A0) control updates.\n",
    "    \"\"\"\n",
    "    def __init__(self, A_c, B_c, C, K, L, h):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            A_c, B_c (np.array): Continuous-time system matrices.\n",
    "            C (np.array): Output matrix.\n",
    "            K (np.array): LQR feedback gain.\n",
    "            L (np.array): Kalman filter gain.\n",
    "            h (float): Sampling period.\n",
    "        \"\"\"\n",
    "        self.n = A_c.shape[0]\n",
    "        \n",
    "        # Discretize the system matrices\n",
    "        self.A = expm(A_c * h)\n",
    "        self.B = np.linalg.inv(A_c) @ (self.A - np.eye(self.n)) @ B_c\n",
    "        self.C = C\n",
    "        self.K = K\n",
    "        self.L = L\n",
    "\n",
    "        # Augmented matrix for successful update (Eq. 2)\n",
    "        # X = [x, x_hat]^T, state dimension is 2n\n",
    "        self.A1 = np.block([\n",
    "            [self.A, -self.B @ self.K],\n",
    "            [self.L @ self.C, self.A - self.L @ self.C - self.B @ self.K]\n",
    "        ])\n",
    "\n",
    "        # Augmented matrix for missed update (Eq. 3)\n",
    "        self.A0 = np.block([\n",
    "            [self.A, -self.B @ self.K],\n",
    "            [np.zeros((self.n, self.n)), np.eye(self.n)]\n",
    "        ])\n",
    "        \n",
    "        # Helper matrices for SSCD calculation\n",
    "        self.I = np.eye(self.n * 2)\n",
    "        self.O = np.zeros_like(self.A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf47357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define a Sample System (e.g., a double integrator) ---\n",
    "# This is a placeholder for a real system model from a CPS application.\n",
    "# Continuous-time state-space representation\n",
    "h = 0.04  # Sampling period\n",
    "A_c = np.array([[0, 1], [0, 0]])\n",
    "B_c = np.array([[0], [1]])\n",
    "C = np.array([[1, 0]])\n",
    "\n",
    "# Dummy gains for K (controller) and L (observer).\n",
    "# In a real scenario, these would be designed (e.g., via LQR/Kalman).\n",
    "K = np.array([[1, 2]])\n",
    "L = np.array([[0.5], [0.1]])\n",
    "\n",
    "# Create the closed-loop system object\n",
    "# system = ClosedLoopSystem(A_c, B_c, C, K, L, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed11e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set Algorithm Inputs ---\n",
    "# Desired GUES decay rate (must be negative)\n",
    "gamma_star = -0.05\n",
    "\n",
    "# Safe state space X_S: [x, x_dot, x_hat, x_dot_hat]\n",
    "# Here, we only constrain the physical states x and x_dot.\n",
    "# The observer states are allowed to vary more widely.\n",
    "safe_space_bounds = [\n",
    "    (-2.0, 2.0),    # position\n",
    "    (-2.0, 2.0),    # velocity\n",
    "    (-10.0, 10.0),  # estimated position\n",
    "    (-10.0, 10.0)   # estimated velocity\n",
    "]\n",
    "\n",
    "# Grid granularity for partitioning X_S\n",
    "grid_delta = [1.0, 1.0, 5.0, 5.0]\n",
    "dims = len(grid_delta)\n",
    "partitions = []\n",
    "\n",
    "# Use Polytope for partitioning\n",
    "for point in itertools.product(*[np.arange(safe_space_bounds[i][0], safe_space_bounds[i][1], grid_delta[i]) for i in range(dims)]):\n",
    "    # Each partition is a box, but represented as a Polytope\n",
    "    A = []\n",
    "    b = []\n",
    "    for i in range(dims):\n",
    "        # x_i >= lower_bound  =>  -x_i <= -lower_bound\n",
    "        # x_i <= upper_bound  =>   x_i <= upper_bound\n",
    "        lower = point[i]\n",
    "        upper = point[i] + grid_delta[i]\n",
    "        a = np.zeros(dims)\n",
    "        a[i] = 1\n",
    "        A.append(a)\n",
    "        b.append(upper)\n",
    "        a = np.zeros(dims)\n",
    "        a[i] = -1\n",
    "        A.append(a)\n",
    "        b.append(-lower)\n",
    "    partitions.append(Polytope(np.array(A), np.array(b)))\n",
    "print(f\"Step 1: Partitioned safe space into {len(partitions)} grid cells using Polytope.\")\n",
    "\n",
    "# Plot only the physical state dimensions: x (position) and x_dot (velocity)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "print(type(partitions[0]))\n",
    "print(dir(partitions[0]))\n",
    "for p in partitions:\n",
    "    # For Polytope, extract bounds for x and x_dot (first two dimensions)\n",
    "    # Each polytope is defined by Ax <= b, but here we know it's a box\n",
    "    # Find min/max for x and x_dot\n",
    "    x_min = -np.inf\n",
    "    x_max = np.inf\n",
    "    v_min = -np.inf\n",
    "    v_max = np.inf\n",
    "    for a, b_val in zip(p.A, p.b):\n",
    "        if a[0] == 1: x_max = min(x_max, b_val)\n",
    "        if a[0] == -1: x_min = max(x_min, -b_val)\n",
    "        if a[1] == 1: v_max = min(v_max, b_val)\n",
    "        if a[1] == -1: v_min = max(v_min, -b_val)\n",
    "    rect = plt.Rectangle((x_min, v_min), x_max-x_min, v_max-v_min, edgecolor='blue', facecolor='none', lw=1)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "ax.set_xlabel('Position (x)')\n",
    "ax.set_ylabel('Velocity (x_dot)')\n",
    "ax.set_title('Safe State Space Partitions (Physical States)')\n",
    "ax.set_xlim(safe_space_bounds[0])\n",
    "ax.set_ylim(safe_space_bounds[1])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_xlabel('Position (x)')\n",
    "ax.set_ylabel('Velocity (x_dot)')\n",
    "ax.set_title('Safe State Space Partitions (Physical States)')\n",
    "ax.set_xlim(safe_space_bounds[0])\n",
    "ax.set_ylim(safe_space_bounds[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb017993",
   "metadata": {},
   "source": [
    "# --- Run the Algorithm ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_cm_guess = k // 2\n",
    "a0 = mkwhsa(clsys, gamma_star, 0, k, initial_cm_guess)\n",
    "nl = len(a0)\n",
    "cm_bar = max(a0.keys()) if a0 else 0\n",
    "m_bar_max = k - (k // (cm_bar + 1)) if cm_bar > -1 else 0\n",
    "print(f\"Step 2-3: Initial analysis -> {nl} locations, Max consecutive miss (CM)={cm_bar}, Max total miss (M)={m_bar_max}\")\n",
    "\n",
    "# Line 4: Initialize the specification list\n",
    "spec_list = [{'X': [], 'm_bar': m, 'cm_bar': cm_bar, 'cm': 0, 'K': k} for m in range(m_bar_max + 1)]\n",
    "\n",
    "# Line 5: Initialize Safety Guard (SG) data structure\n",
    "sg = {m: {} for m in range(m_bar_max + 1)}\n",
    "\n",
    "# --- Main Loop (Line 6) ---\n",
    "for m_j in range(m_bar_max + 1):\n",
    "    print(f\"\\n--- Verifying for m_bar = {m_j} misses ---\")\n",
    "    \n",
    "    # Line 7: Build WHSA for current miss count\n",
    "    automaton_j = \n",
    "        \n",
    "    # Line 8-9: Grid-wise safety verification\n",
    "    print(\"Step 8-9: Performing grid-wise safety verification...\")\n",
    "    for i, partition in enumerate(partitions):\n",
    "        _, sg[m_j] = verha(automaton_j, partition, x_s, m_j, k, sg[m_j])\n",
    "\n",
    "    # Line 13-17: Derive specifications from SG\n",
    "    print(\"Step 13-17: Deriving specifications from verification results...\")\n",
    "    spec = spec_list[m_j]\n",
    "    all_safe_regions_for_mj = []\n",
    "    \n",
    "    # Find all safe regions from the SG table for this miss count\n",
    "    for jump, regions in sg[m_j].items():\n",
    "        all_safe_regions_for_mj.extend(regions)\n",
    "\n",
    "    # The union represents the total safe initialization area found so far\n",
    "    spec['X'] = union_of_rects(all_safe_regions_for_mj)\n",
    "\n",
    "    # Update max consecutive misses based on what was found to be safe\n",
    "    safe_locations = set(j[0] for j in sg[m_j].keys()) | set(j[1] for j in sg[m_j].keys())\n",
    "    spec['cm_bar'] = max(safe_locations) if safe_locations else 0\n",
    "\n",
    "    # Line 18: MDADT calculation (simplified)\n",
    "    # The paper requires MDADT for SSCD '1'. This ensures recovery.\n",
    "    # We'll use a placeholder value, as a full calculation requires\n",
    "    # solving for Lyapunov functions not fully implemented in mkwhsa.\n",
    "    spec['cm'] = 1 # Minimum 1 successful update for recovery.\n",
    "\n",
    "return [s for s in spec_list if s['X']]\n",
    "\n",
    "# --- Print Results ---\n",
    "print(\"\\n\\n--- Final Synthesized Safe Weakly Hard Specifications ---\")\n",
    "if not final_specifications:\n",
    "    print(\"No safe specifications could be found.\")\n",
    "else:\n",
    "    for i, spec in enumerate(final_specifications):\n",
    "        print(f\"\\nSpecification #{i+1}:\")\n",
    "        print(f\"  (m_bar, cm_bar, cm, K) = ({spec['m_bar']}, {spec['cm_bar']}, {spec['cm']}, {spec['K']})\")\n",
    "        print(f\"  Description: Allow max {spec['m_bar']} total misses and {spec['cm_bar']} consecutive misses in {spec['K']} steps.\")\n",
    "        print(f\"  Requires at least {spec['cm']} consecutive successful updates for recovery.\")\n",
    "        print(f\"  Safe Initial Regions (X):\")\n",
    "        if not spec['X']:\n",
    "            print(\"    None found.\")\n",
    "        else:\n",
    "            for region in spec['X']:\n",
    "                print(f\"    - {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831775e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b5bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ac5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPUClosedLoopSystem:\n",
    "    \"\"\"\n",
    "    GPU-accelerated version of ClosedLoopSystem\n",
    "    \"\"\"\n",
    "    def __init__(self, A_c, B_c, C, K, L, h):\n",
    "        self.n = A_c.shape[0]\n",
    "        \n",
    "        # Move matrices to GPU\n",
    "        self.A_c_gpu = cp.array(A_c)\n",
    "        self.B_c_gpu = cp.array(B_c)\n",
    "        self.C_gpu = cp.array(C)\n",
    "        self.K_gpu = cp.array(K)\n",
    "        self.L_gpu = cp.array(L)\n",
    "        \n",
    "        # Discretize the system matrices on GPU\n",
    "        self.A_gpu = cp.array(expm(A_c * h))  # Keep expm on CPU as it's not available in CuPy\n",
    "        self.B_gpu = cp.linalg.inv(self.A_c_gpu) @ (self.A_gpu - cp.eye(self.n)) @ self.B_c_gpu\n",
    "        \n",
    "        # Augmented matrix for successful update\n",
    "        self.A1 = cp.block([\n",
    "            [self.A_gpu, -self.B_gpu @ self.K_gpu],\n",
    "            [self.L_gpu @ self.C_gpu, self.A_gpu - self.L_gpu @ self.C_gpu - self.B_gpu @ self.K_gpu]\n",
    "        ])\n",
    "\n",
    "        # Augmented matrix for missed update\n",
    "        self.A0 = cp.block([\n",
    "            [self.A_gpu, -self.B_gpu @ self.K_gpu],\n",
    "            [cp.zeros((self.n, self.n)), cp.eye(self.n)]\n",
    "        ])\n",
    "        \n",
    "        self.I = cp.eye(self.n * 2)\n",
    "        self.O = cp.zeros_like(self.A1)\n",
    "        \n",
    "    def to_cpu(self):\n",
    "        \"\"\"Convert all matrices back to CPU for compatibility with existing code\"\"\"\n",
    "        return {\n",
    "            'A1': cp.asnumpy(self.A1),\n",
    "            'A0': cp.asnumpy(self.A0),\n",
    "            'I': cp.asnumpy(self.I),\n",
    "            'O': cp.asnumpy(self.O)\n",
    "        }\n",
    "        \n",
    "    def batch_compute_trajectories(self, initial_states, sequence):\n",
    "        \"\"\"\n",
    "        Compute multiple system trajectories in parallel on GPU\n",
    "        \n",
    "        Args:\n",
    "            initial_states: Array of initial states (batch_size x state_dim)\n",
    "            sequence: Array of 1s and 0s indicating successful/missed updates\n",
    "        \"\"\"\n",
    "        states_gpu = cp.array(initial_states)\n",
    "        sequence_gpu = cp.array(sequence)\n",
    "        \n",
    "        trajectories = []\n",
    "        trajectories.append(cp.asnumpy(states_gpu))\n",
    "        \n",
    "        for update in sequence_gpu:\n",
    "            if update:\n",
    "                states_gpu = self.A1 @ states_gpu.T\n",
    "            else:\n",
    "                states_gpu = self.A0 @ states_gpu.T\n",
    "            trajectories.append(cp.asnumpy(states_gpu.T))\n",
    "            \n",
    "        return np.array(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b212bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of GPU-accelerated system\n",
    "def verify_partitions_gpu(system_gpu, partitions, sequence):\n",
    "    \"\"\"\n",
    "    Parallel verification of multiple partitions using GPU\n",
    "    \"\"\"\n",
    "    # Convert partitions to initial states\n",
    "    initial_states = np.array([p.center for p in partitions])\n",
    "    \n",
    "    # Compute all trajectories in parallel\n",
    "    trajectories = system_gpu.batch_compute_trajectories(initial_states, sequence)\n",
    "    \n",
    "    # Verify safety conditions (can be done on CPU as it's less compute-intensive)\n",
    "    safe_partitions = []\n",
    "    for i, trajectory in enumerate(trajectories):\n",
    "        if is_trajectory_safe(trajectory):  # Define this based on your safety conditions\n",
    "            safe_partitions.append(partitions[i])\n",
    "    \n",
    "    return safe_partitions\n",
    "\n",
    "# Convert existing system to GPU version\n",
    "system_gpu = GPUClosedLoopSystem(A_c, B_c, C, K, L, h)\n",
    "\n",
    "# Example sequence of updates (1=success, 0=miss)\n",
    "test_sequence = np.array([1, 0, 1, 1, 0, 1])\n",
    "\n",
    "# Time both CPU and GPU versions for comparison\n",
    "import time\n",
    "\n",
    "print(\"Testing performance comparison:\")\n",
    "\n",
    "# CPU timing\n",
    "start_time = time.time()\n",
    "# Your existing verification code here\n",
    "cpu_time = time.time() - start_time\n",
    "print(f\"CPU time: {cpu_time:.4f} seconds\")\n",
    "\n",
    "# GPU timing\n",
    "start_time = time.time()\n",
    "safe_regions_gpu = verify_partitions_gpu(system_gpu, partitions, test_sequence)\n",
    "gpu_time = time.time() - start_time\n",
    "print(f\"GPU time: {gpu_time:.4f} seconds\")\n",
    "print(f\"Speedup: {cpu_time/gpu_time:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
